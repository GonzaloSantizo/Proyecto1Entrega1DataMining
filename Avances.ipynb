{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostic\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as smd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.diagnostic as diag\n",
    "from scipy.stats import normaltest\n",
    "import random\n",
    "from sklearn.feature_selection import SequentialFeatureSelector #Para stepwise\n",
    "from sklearn.linear_model import RidgeCV, Ridge #Para Ridge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.style.use('ggplot')\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df = pd.read_csv('train.csv', encoding='latin1')\n",
    "\n",
    "houses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploratory data analysis\n",
    "houses_df.describe()\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(houses_df['LotArea'], houses_df['SalePrice'])\n",
    "plt.xlabel('Lot Area (ft^2)')\n",
    "plt.ylabel('Sale Price ($)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
    " 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
    " '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
    " 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
    " 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
    " 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
    " 'MiscVal', 'MoSold', 'YrSold', 'SalePrice']\n",
    "\n",
    "numeric = houses_df[numeric_columns]\n",
    "numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = numeric.drop(['BsmtFinSF2', '2ndFlrSF', 'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "            'HalfBath', 'Fireplaces', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch','ScreenPorch', \n",
    "            'PoolArea', 'MiscVal'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = numeric[numeric[\"SalePrice\"] < 700000]\n",
    "numeric = numeric[numeric[\"LotArea\"] < 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X = numeric.drop(\"SalePrice\", axis=1)\n",
    "y = numeric[\"SalePrice\"]\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Si se proporciona un conjunto de datos de prueba adicional, se puede usar como conjunto de validación\n",
    "\n",
    "# Si no, se puede dividir aún más el conjunto de prueba para tener un conjunto de validación separado\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # División 80/20 entre entrenamiento y validación\n",
    "\n",
    "# Imprimir los tamaños de los conjuntos resultantes\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(X_train))\n",
    "print(\"Tamaño del conjunto de validación:\", len(X_val))\n",
    "print(\"Tamaño del conjunto de prueba:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variable predictora\n",
    "X = X_train['GrLivArea']\n",
    "\n",
    "# Añadir una constante para el término de intercepción\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Modelo de regresión lineal\n",
    "model = sm.OLS(y_train, X).fit()\n",
    "\n",
    "# Resumen del modelo\n",
    "print(model.summary())\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Gráfico de dispersión y línea de regresión\n",
    "plt.scatter(X_train['GrLivArea'], y_train, color='blue', label='Actual')\n",
    "plt.plot(X_train['GrLivArea'], predictions, color='red', linewidth=2, label='Predicted')\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('Sale Price')\n",
    "plt.title('Univariate Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de residuos\n",
    "residuals = y_train - predictions\n",
    "plt.scatter(X_train['GrLivArea'], residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Añadir una constante para el término de intercepción\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Modelo de regresión lineal\n",
    "model = sm.OLS(y_train, X_train_const).fit()\n",
    "\n",
    "# Resumen del modelo\n",
    "print(model.summary())\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.predict(X_train_const)\n",
    "\n",
    "# Gráfico de dispersión entre valores reales y predichos\n",
    "plt.scatter(y_train, predictions)\n",
    "plt.xlabel('Actual Sale Price')\n",
    "plt.ylabel('Predicted Sale Price')\n",
    "plt.title('Actual vs Predicted Sale Price')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de residuos\n",
    "residuals = y_train - predictions\n",
    "plt.scatter(predictions, residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Sale Price')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X = numeric.drop(\"SalePrice\", axis=1)\n",
    "y = numeric[\"SalePrice\"]\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Si se proporciona un conjunto de datos de prueba adicional, se puede usar como conjunto de validación\n",
    "\n",
    "# Si no, se puede dividir aún más el conjunto de prueba para tener un conjunto de validación separado\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # División 80/20 entre entrenamiento y validación\n",
    "\n",
    "# Imprimir los tamaños de los conjuntos resultantes\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(X_train))\n",
    "print(\"Tamaño del conjunto de validación:\", len(X_val))\n",
    "print(\"Tamaño del conjunto de prueba:\", len(X_test))\n",
    "\n",
    "# Añadir una constante para el término de intercepción\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Modelo de regresión lineal\n",
    "model = sm.OLS(y_train, X_train_const).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif[\"features\"] = X_train.columns\n",
    "\n",
    "print(vif)\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = model.rsquared\n",
    "print('R-squared:', r_squared)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "adjusted_r_squared = model.rsquared_adj\n",
    "print('Adjusted R-squared:', adjusted_r_squared)\n",
    "# Check for overfitting\n",
    "predictions_val = model.predict(sm.add_constant(X_val))\n",
    "mse_train = mean_squared_error(y_train, predictions)\n",
    "mse_val = mean_squared_error(y_val, predictions_val)\n",
    "\n",
    "print('Training MSE:', mse_train)\n",
    "print('Validation MSE:', mse_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 y 10\n",
    "\n",
    "\n",
    "# elegimos variables con base a lasso\n",
    "# Create a lasso regressor\n",
    "model = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the regressor to the data\n",
    "rfe = RFE(model, n_features_to_select=6)\n",
    "\n",
    "# Fit the model\n",
    "fit = rfe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)\n",
    "\n",
    "# Seleccionar las características seleccionadas\n",
    "\n",
    "selected_features = X_train.columns[fit.support_]\n",
    "print(\"Selected features: \", selected_features)\n",
    "\n",
    "X = numeric[selected_features]\n",
    "y = numeric[\"SalePrice\"]\n",
    "\n",
    "\n",
    "# Eliminamos las variables con VIF alto\n",
    "# X=numeric\n",
    "# X = numeric.drop([\"SalePrice\", ], axis=1)  \n",
    "# y = numeric[\"SalePrice\"]\n",
    "\n",
    "# Juntar OverQual y OverCond (promedio)\n",
    "\n",
    "# X[\"OverallQualCond\"] = (X[\"OverallQual\"] + X[\"OverallCond\"]) / 2\n",
    "# X = X.drop([\"OverallQual\", \"OverallCond\"], axis=1)\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Si no, se puede dividir aún más el conjunto de prueba para tener un conjunto de validación separado\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # División 80/20 entre entrenamiento y validación\n",
    "\n",
    "# Imprimir los tamaños de los conjuntos resultantes\n",
    "print(\"Tamaño del conjunto de entrenamiento:\",  X_train.shape)\n",
    "print(\"Tamaño del conjunto de validación:\",  X_val.shape)\n",
    "print(\"Tamaño del conjunto de prueba:\" ,X_test.shape)\n",
    "\n",
    "# Añadir una constante para el término de intercepción\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Modelo de regresión lineal\n",
    "model = sm.OLS(y_train, X_train_const).fit()\n",
    "\n",
    "residuals = y_train - model.predict(X_train_const)\n",
    "\n",
    "# Crear la gráfica de residuos\n",
    "plt.scatter(model.predict(X_train_const), residuals)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Sale Price')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "y_pred = model.predict(sm.add_constant(X_train))\n",
    "\n",
    "# Calcular el MSE\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "\n",
    "# Calcular el RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir una constante al conjunto de prueba\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "# Calcular las predicciones del modelo en el conjunto de prueba\n",
    "y_pred_test = model.predict(X_test_const)\n",
    "\n",
    "# Calcular el MSE en el conjunto de prueba\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"MSE (test):\", mse_test)\n",
    "\n",
    "# Calcular el MAE en el conjunto de prueba\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(\"MAE (test):\", mae_test)\n",
    "\n",
    "# Calcular el RMSE en el conjunto de prueba\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "print(\"RMSE (test):\", rmse_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear un gráfico de dispersión de los valores reales vs las predicciones\n",
    "plt.scatter(y_test, y_pred_test)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Valores Reales vs Predicciones')\n",
    "\n",
    "# Dibujar una línea diagonal (indicando un modelo perfecto)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try a different model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Use cross-validation\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Take the square root and make positive (because cross_val_score returns negative values for MSE)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"RMSE Scores:\", rmse_scores)\n",
    "print(\"RMSE Mean:\", rmse_scores.mean())\n",
    "print(\"RMSE Standard Deviation:\", rmse_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "model = Lasso(alpha=0.1)\n",
    "rfe = RFE(model, n_features_to_select=3)\n",
    "fit = rfe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model\n",
    "model = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculate MSE and RMSE\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "print(\"MSE (test):\", mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(\"MAE (test):\", mae_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "print(\"RMSE (test):\", rmse_test)\n",
    "\n",
    "# Plot the predictions\n",
    "plt.scatter(y_test, y_pred_test)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Valores Reales vs Predicciones')\n",
    "\n",
    "# Dibujar una línea diagonal (indicando un modelo perfecto)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
